{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3798 tracks fetched\n",
      "2575 artists fetched\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import pickle\n",
    "\n",
    "client_id = 'b69a9985fa8842deb0691b2d0e3f0b69'\n",
    "client_secret = 'd9e9ae2924174c139a5a9ccb303f9f3a'\n",
    "redirect_uri = 'http://localhost/'\n",
    "\n",
    "username = '22mrmbu7oumkrb56tcsclawdi'\n",
    "\n",
    "token = util.prompt_for_user_token(username, 'user-library-read', client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri)\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)\n",
    "tracks = []\n",
    "\n",
    "offset = 0\n",
    "while True:\n",
    "    track_set = sp.current_user_saved_tracks(limit=50, offset=offset)['items']\n",
    "    if track_set:\n",
    "        tracks += track_set\n",
    "    else:\n",
    "        break\n",
    "    offset += 50\n",
    "print(\"%d tracks fetched\" % len(tracks))\n",
    "\n",
    "\n",
    "try:\n",
    "    with open('artist_names', 'rb') as file:\n",
    "        artist_names = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    artist_names = {}\n",
    "    \n",
    "artist_tracks = {}\n",
    "all_artists = set()\n",
    "for i in range(len(tracks)):\n",
    "    tracks[i] = tracks[i]['track']\n",
    "    track_id = tracks[i]['id']\n",
    "    \n",
    "    for artist in tracks[i]['artists']:\n",
    "        if artist['id'] not in artist_tracks:\n",
    "            artist_tracks[artist['id']] = [track_id]\n",
    "        else:\n",
    "            artist_tracks[artist['id']].append(track_id)\n",
    "    \n",
    "        all_artists.add(artist['id'])\n",
    "        artist_names[artist['id']] = artist['name']\n",
    "        \n",
    "print(\"%d artists fetched\" % len(artist_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres fetched\n",
      "100/2575 artists processed, 0 fetched\n",
      "200/2575 artists processed, 0 fetched\n",
      "300/2575 artists processed, 0 fetched\n",
      "400/2575 artists processed, 0 fetched\n",
      "500/2575 artists processed, 0 fetched\n",
      "600/2575 artists processed, 0 fetched\n",
      "700/2575 artists processed, 0 fetched\n",
      "800/2575 artists processed, 0 fetched\n",
      "900/2575 artists processed, 0 fetched\n",
      "1000/2575 artists processed, 0 fetched\n",
      "1100/2575 artists processed, 0 fetched\n",
      "1200/2575 artists processed, 0 fetched\n",
      "1300/2575 artists processed, 0 fetched\n",
      "1400/2575 artists processed, 0 fetched\n",
      "1500/2575 artists processed, 0 fetched\n",
      "1600/2575 artists processed, 0 fetched\n",
      "1700/2575 artists processed, 0 fetched\n",
      "1800/2575 artists processed, 0 fetched\n",
      "1900/2575 artists processed, 0 fetched\n",
      "2000/2575 artists processed, 0 fetched\n",
      "2100/2575 artists processed, 0 fetched\n",
      "2200/2575 artists processed, 0 fetched\n",
      "2300/2575 artists processed, 0 fetched\n",
      "2400/2575 artists processed, 0 fetched\n",
      "2500/2575 artists processed, 0 fetched\n",
      "2 unnamed artists found, fetching names...\n",
      "All artists processed\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def chunks(n, x):\n",
    "    return [x[i:i + n] for i in range(0, len(x), n)]\n",
    "\n",
    "artist_genres = {}\n",
    "for chunk in chunks(50, list(artist_tracks.keys())):\n",
    "    for artist in sp.artists(chunk)['artists']:\n",
    "        id = artist['id']\n",
    "        artist_genres[id] = artist['genres']\n",
    "print(\"Genres fetched\")\n",
    "\n",
    "try:\n",
    "    G = nx.read_graphml('related_artists.graphml')\n",
    "except FileNotFoundError:\n",
    "    G = nx.Graph()\n",
    "\n",
    "try:\n",
    "    with open('fetched_artists', 'rb') as file:\n",
    "        fetched_artists = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    fetched_artists = set()\n",
    "    \n",
    "i = 0\n",
    "not_found = 0\n",
    "for artist_id in all_artists:\n",
    "    if artist_id not in fetched_artists:\n",
    "        related_list = sp.artist_related_artists(artist_id)['artists']\n",
    "        not_found += 1\n",
    "        fetched_artists.add(artist_id)\n",
    "\n",
    "        for related in related_list:\n",
    "            artist_names[related['id']] = related['name']\n",
    "            G.add_edge(artist_id, related['id'])\n",
    "\n",
    "            if related['id'] not in fetched_artists:\n",
    "                sub_related_list = sp.artist_related_artists(related['id'])['artists']\n",
    "                not_found += 1\n",
    "                fetched_artists.add(related['id'])\n",
    "\n",
    "                for sub_related in sub_related_list:\n",
    "                    artist_names[sub_related['id']] = sub_related['name']\n",
    "                    G.add_edge(related['id'], sub_related['id'])\n",
    "\n",
    "\n",
    "    #             ssub_related_list = sp.artist_related_artists(sub_related['id'])['artists']\n",
    "    #             for ssub_related in ssub_related_list:\n",
    "    #                 artist_names[ssub_related['id']] = artist['name']\n",
    "    #                 G.add_edge(sub_related['id'], ssub_related['id'])\n",
    "\n",
    "    i += 1\n",
    "    if i % 100 ==0:\n",
    "        print(\"%d/%d artists processed, %d fetched\" % (i, len(all_artists), not_found))\n",
    "        \n",
    "for artist in list(artist_tracks.keys()):\n",
    "    if not G.has_node(artist):\n",
    "        del artist_tracks[artist]\n",
    "        all_artists.remove(artist)\n",
    "\n",
    "unnamed_artists = []\n",
    "for artist in G.nodes:\n",
    "    if artist not in artist_names:\n",
    "        unnamed_artists.append(artist)\n",
    "        \n",
    "print(\"%s unnamed artists found, fetching names...\" % len(unnamed_artists))\n",
    "for chunk in chunks(50, unnamed_artists):\n",
    "    for artist in sp.artists(chunk)['artists']:\n",
    "        artist_names[artist['id']] = artist['name']\n",
    "        \n",
    "nx.write_graphml(G, 'related_artists.graphml')\n",
    "with open('fetched_artists', 'wb') as file:\n",
    "    pickle.dump(fetched_artists, file)\n",
    "with open('artist_names', 'wb') as file:\n",
    "    pickle.dump(artist_names, file)\n",
    "\n",
    "print(\"All artists processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(G.nodes)\n",
    "for i in range(len(degrees)):\n",
    "    degree = 0\n",
    "    artist = degrees[i]\n",
    "    for neighbor in nx.neighbors(G, artist):\n",
    "        if neighbor in artist_tracks:\n",
    "            degree += len(artist_tracks[neighbor])\n",
    "    degrees[i] = (artist, degree)\n",
    "\n",
    "degrees.sort(key=lambda tup: tup[1], reverse=True)\n",
    "degrees = [node for node in degrees if node[0] not in artist_tracks]\n",
    "degrees = degrees[:100]\n",
    "top_artists = [node[0] for node in degrees]\n",
    "\n",
    "for chunk in chunks(50, top_artists):\n",
    "    for artist in sp.artists(chunk)['artists']:\n",
    "        id = artist['id']\n",
    "        artist_genres[id] = artist['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes: 83079\n",
      "Graph edges: 362226\n",
      "Graph components: 7\n",
      "0:07:04.137179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "print(\"Graph nodes:\", nx.number_of_nodes(G))\n",
    "print(\"Graph edges:\", nx.number_of_edges(G))\n",
    "print(\"Graph components:\", nx.number_connected_components(G))\n",
    "\n",
    "artists = list(artist_tracks.keys()) + top_artists\n",
    "distance = np.zeros((len(artists), len(artists)))\n",
    "start = datetime.now()\n",
    "iters = 0\n",
    "\n",
    "with Pool(3) as pool:\n",
    "    paths = pool.map(partial(nx.single_source_shortest_path_length, G), artists)\n",
    "\n",
    "i = 0\n",
    "for lengths in paths:\n",
    "    source = artists[i]\n",
    "    for j in range(len(artists)):\n",
    "        target = artists[j]\n",
    "        if target in lengths:\n",
    "            distance[i][j] = lengths[target]\n",
    "        else:\n",
    "            distance[i][j] = np.inf\n",
    "    iters += 1\n",
    "    i += 1\n",
    "    \n",
    "print(datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\manifold\\spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "6 124\n",
      "2 254\n",
      "4 332\n",
      "0 626\n",
      "5 366\n",
      "1 397\n",
      "3 325\n",
      "7 141\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cluster\n",
    "import sklearn.metrics\n",
    "\n",
    "connectivity = nx.to_numpy_matrix(G, nodelist=artists)\n",
    "similarity = np.exp(-distance / distance[ np.isfinite(distance) ].std())\n",
    "# for n_clusters in range(2, 13):\n",
    "# dist = np.copy(distance)\n",
    "# max_value = dist[ np.isfinite(dist) ].max()\n",
    "# print(max_value)\n",
    "# for i in range(len(dist)):\n",
    "#     for j in range(len(dist)):\n",
    "#         if dist[i][j] == np.inf:\n",
    "#             dist[i][j] = max_value * 2\n",
    "\n",
    "#     clustering = sklearn.cluster.AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average', compute_full_tree=True).fit_predict(dist)\n",
    "# clustering = sklearn.cluster.DBSCAN(eps=3, min_samples=1, metric='precomputed', n_jobs=-1).fit_predict(dist)\n",
    "#     print(np.unique(clustering))\n",
    "#     print(\"%d cluster silhouette:\" % len(np.unique(clustering)), sklearn.metrics.silhouette_score(dist, clustering, metric='precomputed'))\n",
    "# print(sklearn.metrics.silhouette_score(dist, clustering, metric='precomputed'))\n",
    "\n",
    "clustering = sklearn.cluster.SpectralClustering(n_clusters=8, affinity='precomputed').fit_predict(similarity)\n",
    "# clustering = sklearn.cluster.AgglomerativeClustering(n_clusters=8, affinity='precomputed', linkage='average', compute_full_tree=True).fit_predict(dist)\n",
    "print(np.unique(clustering))\n",
    "artist_cluster = {}\n",
    "cluster_artists = {}\n",
    "for i in range(len(artists)):\n",
    "    artist_cluster[artists[i]] = clustering[i]\n",
    "    if clustering[i] not in cluster_artists:\n",
    "        cluster_artists[clustering[i]] = [artists[i]]\n",
    "    else:\n",
    "        cluster_artists[clustering[i]].append(artists[i])\n",
    "for clus in cluster_artists:\n",
    "    print(clus, len(cluster_artists[clus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {'cluster': [], 'genre': [], 'count': []}\n",
    "for cluster in cluster_artists:\n",
    "    genre_count = dict()\n",
    "    total_tracks = 0\n",
    "    for artist in cluster_artists[cluster]:\n",
    "        if artist not in artist_tracks:\n",
    "            continue\n",
    "        for genre in artist_genres[artist]:\n",
    "            if genre in genre_count:\n",
    "                genre_count[genre] += len(artist_tracks[artist])\n",
    "            else:\n",
    "                genre_count[genre] = len(artist_tracks[artist])\n",
    "        total_tracks += len(artist_tracks[artist])\n",
    "    for genre, count in genre_count.items():\n",
    "        counts['cluster'].append(cluster)\n",
    "        counts['genre'].append(genre)\n",
    "        counts['count'].append(count / total_tracks)\n",
    "\n",
    "counts = pd.DataFrame(counts)\n",
    "counts.sort_values('count', ascending=False, inplace=True)\n",
    "original_counts = counts.copy()\n",
    "\n",
    "clusters_to_name = set(counts['cluster'].unique())\n",
    "playlists = {}\n",
    "cluster_names = {}\n",
    "while clusters_to_name:\n",
    "    cluster = counts.iloc[0]['cluster']\n",
    "    name = counts.iloc[0]['genre']\n",
    "    playlists[name] = cluster\n",
    "    cluster_names[cluster] = name\n",
    "    counts = counts[ (counts['cluster']!=cluster) & (counts['genre']!=name) ]\n",
    "    clusters_to_name.remove(cluster)\n",
    "    \n",
    "playlist_tracks = dict()\n",
    "from collections import OrderedDict\n",
    "for name in playlists:\n",
    "    playlist_tracks[name] = []\n",
    "    cluster = playlists[name]\n",
    "    for artist in cluster_artists[cluster]:\n",
    "        if artist in artist_tracks:\n",
    "            playlist_tracks[name] += artist_tracks[artist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'62R1EpHT7Y1OzPA9fVKKP9' in all_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brostep\n",
      "\tTima Dee: 268\n",
      "\tKnife Party: 193\n",
      "\tMicah Martin: 190\n",
      "\tRicky Remedy: 179\n",
      "\tDJ Sliink: 175\n",
      "\tRiot Ten: 172\n",
      "\tAryay: 161\n",
      "\tKayzo: 160\n",
      "\tTeddy Tuxedo: 157\n",
      "\tDoctor P: 154\n",
      "bass trap\n",
      "\tHippie Sabotage: 236\n",
      "\tMadds: 192\n",
      "\tQuix: 164\n",
      "\tDuskus: 148\n",
      "\tAdventure Club: 136\n",
      "\tElectric Mantis: 133\n",
      "\tAlex Barthol: 126\n",
      "\tCRAY: 121\n",
      "\tBig Wild: 119\n",
      "\tMEMBA: 110\n",
      "edm\n",
      "\tDyCy: 226\n",
      "\tKill The Noise Remix: 204\n",
      "\tThomas Gold: 192\n",
      "\tSyn Cole: 184\n",
      "\tBougenvilla: 176\n",
      "\tLuciana: 174\n",
      "\tCobra Effect: 172\n",
      "\tDannic: 162\n",
      "\tInpetto: 136\n",
      "\tBoris Smith: 135\n",
      "indietronica\n",
      "\tHEDO: 201\n",
      "\tKRUE: 146\n",
      "\tFlume: 145\n",
      "\tShlohmo: 140\n",
      "\tJamie XX: 121\n",
      "\tHouse Dj: 116\n",
      "\tLuttrell: 113\n",
      "\tOliver: 95\n",
      "\tNosaj Thing: 91\n",
      "progressive house\n",
      "\tKrewella: 159\n",
      "\tAaron Smith: 155\n",
      "\t16 Bit Lolitas: 117\n",
      "\tJaytech: 104\n",
      "tech house\n",
      "\tDosem: 139\n",
      "\tANNA: 131\n",
      "\tJody Wisternoff: 127\n",
      "\tMihalis Safras: 94\n",
      "rap\n",
      "\tAthletixx: 120\n"
     ]
    }
   ],
   "source": [
    "top_clustered = {}\n",
    "for degree in degrees:\n",
    "    artist = degree[0]\n",
    "    cluster = artist_cluster[artist]\n",
    "    if cluster not in top_clustered:\n",
    "        top_clustered[cluster] = [degree]\n",
    "    else:\n",
    "        top_clustered[cluster].append(degree)\n",
    "        \n",
    "for cluster in top_clustered:\n",
    "    print(cluster_names[cluster])\n",
    "    for degree in top_clustered[cluster][:10]:\n",
    "        print(\"\\t%s: %d\" % (artist_names[degree[0]], degree[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(username, 'playlist-modify-private', client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri)\n",
    "sp = spotipy.Spotify(auth=token)\n",
    "\n",
    "for name in playlist_tracks:\n",
    "    id = sp.user_playlist_create(username, 'sortify '+name, public=False)['id']\n",
    "    for chunk in chunks(100, playlist_tracks[name]):\n",
    "        sp.user_playlist_add_tracks(username, id, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(playlists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
